{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 03 (Individual) - Due Thursday, November 16 at Midnight\n",
    "\n",
    "*Objectives*: Use Spark to process and perform basic analysis on non-relational data, including its DataFrame and SQL interfaces.\n",
    "\n",
    "*Grading criteria*: The tasks should all be completed, and questions should all be answered with Python code, SQL queries, shell commands, and markdown cells.  The notebook itself should be completely reproducible (using AWS EC2 instance based on the provided AMI) from start to finish; another person should be able to use the code to obtain the same results as yours.  Note that you will receive no more than partial credit if you do not add text/markdown cells explaining your thinking when appropriate.\n",
    "\n",
    "\n",
    "*Deadline*: Thursday, November 16 at Midnight  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Setup\n",
    "\n",
    "Begin by setting up Spark and fetching the project data.  \n",
    "\n",
    "**Note**: you may want to use a larger EC2 instance type than normal.  This project was prepared using a `t2.xlarge` instance.  Just remember that the larger the instance, the higher the per-hour charge, so be sure to remember to shut your instance down when you're done, as always.\n",
    "\n",
    "### About the data\n",
    "\n",
    "We will use JSON data from Twitter; we saw an example of this in class.  It should parse cleanly, allowing you to focus on analysis.\n",
    "\n",
    "This data was gathered using GWU Libraries' [data sets](https://tweetsets.library.gwu.edu/datasets) during a game of the MLB World Series featuring the Los Angeles Dodgers and Houston Astros.  This first file tells you a little bit about how it was gathered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First make sure you are working from the right working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This below file provides context and detail information on the files we are going to work with\n",
    "#### in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 9670f3399f774789b7c3e18975d25611-README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important pieces in that metadata are:\n",
    "\n",
    " * It tracked tweets that mentioned \"dodgers\" or \"astros\".  Every item in this set should refer to one or the other, or both.\n",
    " * This data was not deduplicated; we may see individual items more than once.\n",
    " * Data was collected between October 29 and October 30.  Game 5 of the Series was played during this time.\n",
    " \n",
    "You should not need to know anything about baseball to complete this assignment.\n",
    "\n",
    "**Please note**: sometimes social media data contains offensive material.  This data set has not been filtered; if you do come across something inappropriate, please do your best to ignore it if you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data\n",
    "\n",
    "The following files are available:\n",
    "\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_003.json\n",
    " * https://s3.amazonaws.com/2017-dmfa/project-3/9670f3399f774789b7c3e18975d25611_006.json\n",
    " \n",
    "### Q1.1 - Upload the above files to your instance using `wget`.  Verify the file sizes using the command line. \n",
    "\n",
    "Each file should contain exactly 100,000 tweets.  \n",
    "\n",
    "*Note*: you are required to use all files.  It will be easier to process more data if you use a larger EC2 instance type, as suggested above.  Use the exact same set of files throughout the assignment.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the files using wget. Add more if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the files have exactly 100,000 tweets using the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write you code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your reference, here is the text of one Tweet, randomly selected from one of these files.  You might wish to study its structure and refer to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat *.json | shuf -n 1 > example-tweet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(json.load(open(\"example-tweet.json\")), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find several key elements in this example; the text, time, and language of the tweet, whether it was a reply to another user, the user's screen name along with their primary language and other account information like creation date, follower/friend/tweet counts, and perhaps their location.  \n",
    "If there are hashtags, user mentions, or urls present in their tweet, they will be present in the `entities` section; these are not present in every tweet.  If this is a retweet, you will see the original tweet and its information nested within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 - Start up Spark, and verify the file sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our normal startup sequence here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SPARK_HOME'] = '/usr/local/lib/spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkContext(appName='project-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlc = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = sqlc.read.json(\"*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that Spark has loaded the same number of tweets you saw before:\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see exactly the same number of tweets in Spark that you saw on the command line? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Comparing DataFrames and Spark SQL\n",
    "\n",
    "For the next three questions, we will look at operations using both DataFrames and SQL queries. Note that `tweets` is already a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To issue SQL queries, we need to register a table based on `tweets`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all well and good, but how well did schema inference work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.createOrReplaceTempView(\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 - Which 6 languages are most commonly used in tweets?  Verify your result by executing it with both the dataframe and with SQL.\n",
    "\n",
    "Hint: for the dataframe, use `groupBy`, `count`, and `orderBy`.  See the documentation at https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html for details on these and other functions.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 - Which 5 time zones are most common among users?  Verify your result with both the dataframe and SQL.\n",
    "\n",
    "*Note*: for this question, you may leave NULL values present in your results, as a way to help you understand what data is present and what is missing.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and write query using SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 - How many tweets mention the Dodgers?  How many mention the Astros?  How many mention both?\n",
    "\n",
    "You may use either the dataframe or SQL to answer.  Explain why you have chosen that approach.\n",
    "\n",
    "Hint:  you will want to look at the value of the `text` field.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - More complex queries\n",
    "\n",
    "For this section, you may choose to use dataframe queries or SQL.  If you wish, you may verify results by using both, as in Part 2, but this is not required for this section.\n",
    "\n",
    "### Q3.1 - Team mentions by location\n",
    "\n",
    "In which users' locations are the Astros and the Dodgers being mentioned the most?  Consider each team separately, one at a time.  Discuss your findings. Do not count null time_zones or location.\n",
    "\n",
    "Hint:  you may use either the time zones or user-specified locations for this question.\n",
    "\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 - Which Twitter users are being replied to the most?\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "Hint: use the top-level `in_reply_to_screen_name` for this.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrtie your observations here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 - Which 12 verified users have the most followers?  Which 12 unverified users have the most followers?\n",
    "\n",
    "Provide both the screen names (screen_name) and follower counts (followers_count) for each.\n",
    "Verified users -- use verified == 't'\n",
    "\n",
    "Discuss your findings.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your observations here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 - Analyze common words in tweet text\n",
    "\n",
    "Following the example in class, use `tweets.rdd` to find the most common interesting words in tweet text.  To keep it \"interesting\", remove at least 12 common stop words found in tweets, like \"a\", \"an\", \"the\", and \"RT\" (you might want to derive these stop words from initial results).  A simple split on text whitespace like we had in class is sufficient; you do not have to account for punctuation. \n",
    "\n",
    "After you find the most common words, use dataframe or SQL queries to find patterns among how those words are used.  For example, are they more frequently used by Dodgers or Astros fans, or by people in one part of the country over another?  Explore and see what you can find, and discuss your findings.\n",
    "\n",
    "You will notice that common words include words like \"thisteam\" and \"earnhistory\". I would like you to write two queries to investigate whether those two words are used by the Astros or Dodgers\n",
    "\n",
    "Hint: don't forget all the word count pipeline steps we used earlier in class.\n",
    "\n",
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell and add more as appropriate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
